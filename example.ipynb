{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2179081-b6bf-49ab-ae18-88f27e0d2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchkan.data import timeseries\n",
    "from torchkan.models import TKAT, TKAN, ReLUKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d167dc-794c-4521-9135-ef390683d252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3372e6c2-bd6f-449c-b909-6acd5b1186c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hidden = 64\n",
    "num_heads = 4\n",
    "num_embedding = 1\n",
    "n_ahead = 30\n",
    "sequence_length = 5 * n_ahead\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7a913b-3829-45fe-bb2e-cda7f2ab27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_dataloaders(\n",
    "    path = \"torchkan/data/data.parquet\", \n",
    "    n_ahead = 30,\n",
    "    batch_size=16\n",
    "):\n",
    "    # Load California housing dataset\n",
    "    df = timeseries.load_crypto(path)\n",
    "\n",
    "    known_input_df = pd.DataFrame(\n",
    "        index=df.index, \n",
    "        data=np.array([\n",
    "            df.reset_index()['group'].apply(lambda x: (x.hour)).values, \n",
    "            df.reset_index()['group'].apply(lambda x: (x.dayofweek)).values\n",
    "        ]).T, \n",
    "        columns = ['hour', 'dayofweek'])\n",
    "    \n",
    "    X_scaler, X_train, X_test, \\\n",
    "        X_train_unscaled, X_test_unscaled, \\\n",
    "            y_scaler, y_train, y_test, \\\n",
    "                y_train_unscaled, y_test_unscaled, \\\n",
    "                    y_scaler_train, y_scaler_test = \\\n",
    "        timeseries.generate_data_w_known_inputs(df, \n",
    "                                                known_input_df,\n",
    "                                                sequence_length, \n",
    "                                                n_ahead)\n",
    "\n",
    "    # Create data loaders (optional, if you want to batch and shuffle the data)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_train, y_train), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_test, y_test), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b458ed3c-3c9a-43cb-a787-2ab63aaceec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miles/Development/notebooks/torchkan/torchkan/data/timeseries.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(data, dtype=dtype).to(device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([torch.Size([20607, 180, 21]), torch.Size([20607, 30])],\n",
       " [torch.Size([5152, 180, 21]), torch.Size([5152, 30])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, test_loader = get_crypto_dataloaders(n_ahead=n_ahead)\n",
    "[t.shape for t in train_loader.dataset.tensors], [t.shape for t in test_loader.dataset.tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6898d63d-6465-4981-b7f6-f48d483e8723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20607, 180, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = train_loader.dataset.tensors[0].shape\n",
    "torch.split(train_loader.dataset.tensors[0], (1,) * shape[-1], -1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c49e31-ff84-46e5-a505-da8c11178124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20607, 180, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.tensors[0][:, :, 0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af457bbf-7834-4916-9d52-c290592a14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TKAN(\n",
       "  (tkan_cells): ModuleList(\n",
       "    (0): TKANCell(\n",
       "      (tkan_sub_layers): ModuleList(\n",
       "        (0): KANLinear(\n",
       "          (linear): Linear(in_features=180, out_features=180, bias=True)\n",
       "          (layer_norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TKAN(input_size=sequence_length+n_ahead, hidden_size=num_hidden)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c27031-7045-4ed0-82c6-66bd2e5dc298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRN] in_size: 21, hidden_size: 64, out_size: 21\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 2, hidden_size: 64, out_size: 2\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 1, hidden_size: 64, out_size: 64\n",
      "[GRN] in_size: 64, hidden_size: 64, out_size: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TKAT(\n",
       "  (embedding_layer): EmbeddingLayer(\n",
       "    (dense_layers): ModuleList(\n",
       "      (0-20): 21 x Linear(in_features=1, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vsn_past_features): VariableSelectionNetwork(\n",
       "    (mlp_dense): GRN(\n",
       "      (skip_layer): Linear(in_features=21, out_features=21, bias=True)\n",
       "      (hidden_layer_1): Sequential(\n",
       "        (0): Linear(in_features=21, out_features=64, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (hidden_layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (gate_layer): Gate(\n",
       "        (dense_layer): Linear(in_features=64, out_features=21, bias=True)\n",
       "        (gated_layer): Linear(in_features=64, out_features=21, bias=True)\n",
       "      )\n",
       "      (add_and_norm_layer): AddAndNorm(\n",
       "        (norm_layer): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (grn_layers): ModuleList(\n",
       "      (0-20): 21 x GRN(\n",
       "        (skip_layer): Linear(in_features=1, out_features=64, bias=True)\n",
       "        (hidden_layer_1): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (hidden_layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (gate_layer): Gate(\n",
       "          (dense_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (gated_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (add_and_norm_layer): AddAndNorm(\n",
       "          (norm_layer): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vsn_future_features): VariableSelectionNetwork(\n",
       "    (mlp_dense): GRN(\n",
       "      (skip_layer): Linear(in_features=2, out_features=2, bias=True)\n",
       "      (hidden_layer_1): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (hidden_layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (gate_layer): Gate(\n",
       "        (dense_layer): Linear(in_features=64, out_features=2, bias=True)\n",
       "        (gated_layer): Linear(in_features=64, out_features=2, bias=True)\n",
       "      )\n",
       "      (add_and_norm_layer): AddAndNorm(\n",
       "        (norm_layer): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (grn_layers): ModuleList(\n",
       "      (0-1): 2 x GRN(\n",
       "        (skip_layer): Linear(in_features=1, out_features=64, bias=True)\n",
       "        (hidden_layer_1): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (hidden_layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (gate_layer): Gate(\n",
       "          (dense_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (gated_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (add_and_norm_layer): AddAndNorm(\n",
       "          (norm_layer): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): RecurrentLayer(\n",
       "    (layer): TKAN(\n",
       "      (tkan_cells): ModuleList(\n",
       "        (0): TKANCell(\n",
       "          (tkan_sub_layers): ModuleList(\n",
       "            (0): KANLinear(\n",
       "              (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): RecurrentLayer(\n",
       "    (layer): TKAN(\n",
       "      (tkan_cells): ModuleList(\n",
       "        (0): TKANCell(\n",
       "          (tkan_sub_layers): ModuleList(\n",
       "            (0): KANLinear(\n",
       "              (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gate): Gate(\n",
       "    (dense_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (gated_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (add_and_norm): AddAndNorm(\n",
       "    (norm_layer): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (grn): GRN(\n",
       "    (skip_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (hidden_layer_1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (hidden_layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (gate_layer): Gate(\n",
       "      (dense_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (gated_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (add_and_norm_layer): AddAndNorm(\n",
       "      (norm_layer): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (final_dense): Linear(in_features=1728000, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TKAT(\n",
    "            sequence_length=sequence_length, \n",
    "            num_unknown_features=19, \n",
    "            num_known_features=2, \n",
    "            num_embedding=num_embedding, \n",
    "            num_hidden=num_hidden, \n",
    "            num_heads=num_heads, \n",
    "            n_ahead=n_ahead, \n",
    "            use_tkan=True\n",
    "        )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9b7326-a6f5-4fb5-8f82-111bf8288b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLUKAN(\n",
       "  (rk_layers): ModuleList(\n",
       "    (0): ReLUKANLayer(\n",
       "      (conv): Conv2d(1, 1, kernel_size=(8, 180), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ReLUKAN([180,1], 5, 3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f794c7bb-e89e-469b-85b3-d042dac40bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 4321\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# LBFGS is really slow\n",
    "# optimizer = optim.LBFGS(model.parameters(), lr=0.01)\n",
    "# Adam works with very low lr\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0c065c2-efb9-405d-890a-a27bf28bddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    bar = tqdm.tqdm(enumerate(train_loader))\n",
    "    for idx, (data, target) in bar:\n",
    "        data, target = data[...,0:1].to(device), target[...,0:1].to(device)\n",
    "        #print(f\"data: {data.shape}\")\n",
    "\n",
    "        if isinstance(optimizer, optim.LBFGS):\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            loss = optimizer.step(closure)\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.item()\n",
    "            \n",
    "        total_loss += loss\n",
    "        bar.set_postfix({\"loss\": loss, \"avg_loss\": total_loss / (idx+1)})\n",
    "        \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm.tqdm(test_loader)\n",
    "        for data, target in bar:\n",
    "            data, target = data[...,0:1].to(device), target[...,0:1].to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            #pred = output.argmax(dim=1, keepdim=True)\n",
    "            #correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            error = torch.abs(output - target).mean()\n",
    "            bar.set_postfix({\"loss\": loss, \"error\": error})\n",
    "\n",
    "    return total_loss / len(test_loader), correct / len(test_loader.dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e97f8b0-ae64-45db-b984-5f764e066d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 194.24it/s, loss=0.00783, avg_loss=0.00399] \n",
      "100%|█| 322/322 [00:00<00:00, 370.30it/s, loss=tensor(0.0013), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0040, Test Loss: 0.0052, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:07, 170.50it/s, loss=0.00401, avg_loss=0.00387] \n",
      "100%|█| 322/322 [00:01<00:00, 314.82it/s, loss=tensor(0.0016), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.0039, Test Loss: 0.0054, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 185.59it/s, loss=0.00129, avg_loss=0.00392] \n",
      "100%|█| 322/322 [00:00<00:00, 411.90it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.0039, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 199.00it/s, loss=0.015, avg_loss=0.00394]   \n",
      "100%|█| 322/322 [00:00<00:00, 426.46it/s, loss=tensor(0.0023), error=tensor(0.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.0039, Test Loss: 0.0061, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 206.32it/s, loss=0.000538, avg_loss=0.00384]\n",
      "100%|█| 322/322 [00:00<00:00, 435.63it/s, loss=tensor(0.0012), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 190.11it/s, loss=0.00481, avg_loss=0.00377] \n",
      "100%|█| 322/322 [00:00<00:00, 406.28it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 197.80it/s, loss=0.0015, avg_loss=0.00387]  \n",
      "100%|█| 322/322 [00:00<00:00, 417.15it/s, loss=tensor(0.0012), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.0039, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 198.88it/s, loss=0.0101, avg_loss=0.00384]  \n",
      "100%|█| 322/322 [00:01<00:00, 283.51it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.0038, Test Loss: 0.0050, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 187.63it/s, loss=0.00177, avg_loss=0.00385] \n",
      "100%|█| 322/322 [00:00<00:00, 395.13it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 185.29it/s, loss=0.000768, avg_loss=0.00387]\n",
      "100%|█| 322/322 [00:00<00:00, 386.21it/s, loss=tensor(0.0025), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.0039, Test Loss: 0.0073, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 203.51it/s, loss=0.00219, avg_loss=0.0039]  \n",
      "100%|█| 322/322 [00:00<00:00, 423.07it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 0.0039, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 205.04it/s, loss=0.00196, avg_loss=0.00384] \n",
      "100%|█| 322/322 [00:00<00:00, 323.31it/s, loss=tensor(0.0013), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 0.0038, Test Loss: 0.0052, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 207.03it/s, loss=0.00705, avg_loss=0.00385] \n",
      "100%|█| 322/322 [00:00<00:00, 390.89it/s, loss=tensor(0.0011), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 0.0038, Test Loss: 0.0054, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 203.12it/s, loss=0.00121, avg_loss=0.00383] \n",
      "100%|█| 322/322 [00:01<00:00, 267.46it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 204.49it/s, loss=0.0143, avg_loss=0.00381]  \n",
      "100%|█| 322/322 [00:00<00:00, 419.66it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 0.0038, Test Loss: 0.0050, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 204.90it/s, loss=0.00116, avg_loss=0.00377] \n",
      "100%|█| 322/322 [00:00<00:00, 376.90it/s, loss=tensor(0.0015), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.0038, Test Loss: 0.0054, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 188.73it/s, loss=0.00538, avg_loss=0.00379] \n",
      "100%|█| 322/322 [00:00<00:00, 353.30it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 0.0038, Test Loss: 0.0052, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 201.57it/s, loss=0.00127, avg_loss=0.00378] \n",
      "100%|█| 322/322 [00:00<00:00, 427.04it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 189.05it/s, loss=0.000977, avg_loss=0.00376]\n",
      "100%|█| 322/322 [00:00<00:00, 370.68it/s, loss=tensor(0.0015), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 0.0038, Test Loss: 0.0057, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 202.49it/s, loss=0.00139, avg_loss=0.00377] \n",
      "100%|█| 322/322 [00:00<00:00, 405.53it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 192.40it/s, loss=0.00263, avg_loss=0.00378] \n",
      "100%|█| 322/322 [00:00<00:00, 422.31it/s, loss=tensor(0.0011), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 205.76it/s, loss=0.00979, avg_loss=0.00381] \n",
      "100%|█| 322/322 [00:00<00:00, 390.55it/s, loss=tensor(0.0011), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 193.17it/s, loss=0.00116, avg_loss=0.00375] \n",
      "100%|█| 322/322 [00:00<00:00, 370.26it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 0.0038, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 197.86it/s, loss=0.00128, avg_loss=0.00374] \n",
      "100%|█| 322/322 [00:00<00:00, 377.56it/s, loss=tensor(0.0011), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 0.0037, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 185.28it/s, loss=0.00853, avg_loss=0.00373] \n",
      "100%|█| 322/322 [00:00<00:00, 369.23it/s, loss=tensor(0.0029), error=tensor(0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 0.0037, Test Loss: 0.0066, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 203.61it/s, loss=0.0022, avg_loss=0.00374]  \n",
      "100%|█| 322/322 [00:00<00:00, 358.39it/s, loss=tensor(0.0012), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 0.0037, Test Loss: 0.0054, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 187.21it/s, loss=0.00354, avg_loss=0.00376] \n",
      "100%|█| 322/322 [00:00<00:00, 388.80it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 0.0038, Test Loss: 0.0050, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 195.06it/s, loss=0.00196, avg_loss=0.00376] \n",
      "100%|█| 322/322 [00:00<00:00, 427.02it/s, loss=tensor(0.0016), error=tensor(0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 0.0038, Test Loss: 0.0054, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 195.31it/s, loss=0.00762, avg_loss=0.00373] \n",
      "100%|█| 322/322 [00:00<00:00, 396.28it/s, loss=tensor(0.0010), error=tensor(0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 0.0037, Test Loss: 0.0051, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1288it [00:06, 199.03it/s, loss=0.00216, avg_loss=0.00371] \n",
      "100%|█| 322/322 [00:00<00:00, 367.66it/s, loss=tensor(0.0018), error=tensor(0.04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train Loss: 0.0037, Test Loss: 0.0056, Test Acc: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_accuracy = validate(model, test_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, '\n",
    "        f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc606d31-898b-42ef-a07b-8f36109c0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca97d0c0-f79a-49ee-9449-d9252a0313bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20607, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(train_loader.dataset.tensors[0][:, :, 0:1])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e314c5b-9ca2-4831-a7b4-c8dc0222f3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea962fc-65ae-431c-91ef-9f18d00e9f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617c802-56b0-43cb-b0f0-285b173b4c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60503689-1474-4220-858b-0f2b17956271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
